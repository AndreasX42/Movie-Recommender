{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b4fc8-32a3-4e64-a1fa-bd25cbca3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "CONFIG = yaml.safe_load(open(\"../config.yml\"))\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = CONFIG[\"EmbeddingModel\"]\n",
    "model_kwargs = {'device': CONFIG[\"EmbeddingDevice\"]} # \"cuda\"\n",
    "encode_kwargs = {'normalize_embeddings': CONFIG[\"EmbeddingNormalized\"]}\n",
    "model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c08f44-22a5-4fbd-97a5-45bd14281c2b",
   "metadata": {},
   "source": [
    "# movies vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50d278-250b-4750-84a1-9bfbed6cd70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_movie_collection(model: HuggingFaceEmbeddings):\n",
    "    from tqdm.auto import tqdm\n",
    "    import chromadb\n",
    "    \n",
    "    client = chromadb.PersistentClient(path=f\"../{CONFIG['ChromaDBPath']}\")\n",
    "    movie_collection = client.create_collection(\"movies\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "    # movies data preprocessing\n",
    "    movie_df = pd.read_csv(f\"../{CONFIG['MovieCsv']}\")\n",
    "    COLS = [\"movieId\", \"Title\", \"Release Year\", \"Origin/Ethnicity\", \"Director\", \"Cast\", \"genres\", \"Wiki Page\", \"Plot\"]\n",
    "    movie_df = movie_df[COLS]\n",
    "    movie_df['movieId'] = movie_df['movieId'].astype(int).astype(str)\n",
    "    movie_df['Cast'] = movie_df['Cast'].fillna('Unknown')\n",
    "\n",
    "    # create collection in chromadb\n",
    "    # we will use batches of 64\n",
    "    batch_size = 64\n",
    "    \n",
    "    for i in tqdm(range(0, len(movie_df), batch_size)):\n",
    "        \n",
    "        # find end of batch\n",
    "        i_end = min(i+batch_size, len(movie_df))\n",
    "        \n",
    "        # extract batch\n",
    "        batch = movie_df.iloc[i:i_end]\n",
    "        \n",
    "        # generate embeddings for batch, every row gets transformed into string and encoded\n",
    "        embeddings = model.embed_documents(batch[\"Plot\"].tolist())\n",
    "        \n",
    "        # get metadata and documents\n",
    "        meta = batch.drop(\"Plot\", axis=1).to_dict(orient='records')\n",
    "        docs = batch[\"Plot\"].tolist()\n",
    "        \n",
    "        # create IDs\n",
    "        ids = batch[\"movieId\"].values.tolist()\n",
    "        \n",
    "        # add all to upsert list\n",
    "        movie_collection.upsert(ids=ids, embeddings=embeddings, metadatas=meta, documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282608f-8187-4589-8eb4-cb838a0b1366",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_movie_collection(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e65a1-0c05-499c-a073-09d262046bd5",
   "metadata": {},
   "source": [
    "# Users vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829922a-470d-4fca-8011-93f5927abc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_embedding(movieIds: list[str], timestamps: list[int], movie_collection):\n",
    "    max_timestamp = max(timestamps)\n",
    "    decay_factor = 0.1  # You can adjust the decay factor as needed\n",
    "    weights = np.exp(decay_factor * (np.array(timestamps) - max_timestamp))\n",
    "    \n",
    "    # Normalize the weights so that they sum up to 1\n",
    "    weights = weights / weights.sum()\n",
    "    weights = weights.reshape(-1,1)\n",
    "    \n",
    "    # Calculate the weighted average of the vectors\n",
    "    embeddings = np.array(movie_collection.get(ids=movieIds, include=[\"embeddings\"])[\"embeddings\"]).reshape(CONFIG[\"EmbeddingDim\"],-1)\n",
    "    weighted_embedding = embeddings @ weights\n",
    "    \n",
    "    return weighted_embedding.flatten()\n",
    "    \n",
    "def create_user_collection(model: HuggingFaceEmbeddings):\n",
    "    from tqdm.auto import tqdm\n",
    "    import chromadb\n",
    "    \n",
    "    # preprocess user data\n",
    "    users_df = pd.read_csv(f\"../{CONFIG['UserCsv']}\")\n",
    "    COLS = [\"userId\", \"movieId\", \"timestamp\"]\n",
    "    users_df = users_df[COLS]\n",
    "    users_df['userId'] = users_df['userId'].astype(str)\n",
    "    users_df['movieId'] = users_df['movieId'].astype(str)\n",
    "\n",
    "    # load chromadb client and collections\n",
    "    client = chromadb.PersistentClient(path=f\"../{CONFIG['ChromaDBPath']}\")\n",
    "    movie_collection = client.get_collection(\"movies\")\n",
    "    user_collection = client.get_or_create_collection(\"users\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "    for userId in tqdm(users_df.userId.unique()):\n",
    "\n",
    "        user_data = users_df[users_df.userId==userId]\n",
    "        \n",
    "        # find all movieId and timestamps pairs of user\n",
    "        timestamps = user_data.timestamp.to_numpy()\n",
    "        movieIds = user_data.movieId.tolist()\n",
    "        \n",
    "        # get exponential moving average of corresponding embeddings wrt timestamps\n",
    "        embedding = calculate_average_embedding(movieIds, timestamps, movie_collection).tolist()\n",
    "        \n",
    "        # get metadata and documents\n",
    "        meta = {\"userId\": userId, \n",
    "                \"movieIds\": str(movieIds),\n",
    "                \"timestamps\": str(timestamps)\n",
    "               }\n",
    "        \n",
    "        # create IDs\n",
    "        ids = userId\n",
    "        \n",
    "        # add all to upsert list\n",
    "        user_collection.upsert(ids=ids, embeddings=embedding, metadatas=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53501e03-91e8-4082-836f-26edd16c3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_user_collection(model)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
